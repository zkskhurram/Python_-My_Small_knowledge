{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
âš¡ **Subject** : 10 Minutes to pandas â€” Enhanced Guide\
ðŸ–Šï¸ **Author**  : Khurram Shahzad \
ðŸŽ“ **Mentor**  : Dr. Aammar Tufail\
ðŸ”— **Contact** : khurramamq@gmail.com // [https://github.com/zkskhurram/Python_-My_Small_knowledge/edit/main](https://github.com/zkskhurram/Python_-My_Small_knowledge/tree/main)
    "# ðŸš¢ EDA & Data Wrangling on Titanic Dataset (`sns.load_dataset('titanic')`)\n",
    "\n",
    "This notebook performs a full **Exploratory Data Analysis (EDA)** and **data wrangling** pipeline\n",
    "on the Titanic dataset available in seaborn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Titanic Dataset\n",
    "\n",
    "We use seaborn's built-in Titanic dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "print(\"Titanic dataset loaded.\")\n",
    "display(df.head())\n",
    "print(\"Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Info, Data Types, Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrame Info:\")\n",
    "print(\"-\" * 40)\n",
    "df.info()\n",
    "\n",
    "print(\"\\nData Types:\")\n",
    "print(\"-\" * 40)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Values (Count):\")\n",
    "missing_counts = df.isnull().sum()\n",
    "print(missing_counts)\n",
    "\n",
    "print(\"\\nMissing Values (Percentage):\")\n",
    "missing_pct = df.isnull().mean() * 100\n",
    "print(missing_pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Descriptive Statistics & Random Samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numeric Summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nCategorical Summary:\")\n",
    "display(df.describe(include=['object', 'category']))\n",
    "\n",
    "print(\"\\nRandom Sample Rows:\")\n",
    "display(df.sample(5, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understand Variables\n",
    "\n",
    "- Identify numeric & categorical columns\n",
    "- Target variable: `survived`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "\n",
    "print(\"Numeric Columns:\", numeric_cols)\n",
    "print(\"Categorical Columns:\", cat_cols)\n",
    "\n",
    "target_col = 'survived'  # target for modeling\n",
    "print(\"Target Column:\", target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Relationships Between Variables (Correlation, Heatmap, Pairplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "corr = df.corr(numeric_only=True)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Titanic: Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot on a subset of numeric columns\n",
    "num_cols_subset = ['age', 'fare', 'sibsp', 'parch']\n",
    "sns.pairplot(df[num_cols_subset].dropna())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Brainstorming: Scaling & Outliers\n",
    "\n",
    "### 6.1 Example: Scaling `age` and `fare`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_to_scale = ['age', 'fare']\n",
    "df_scaled = df.copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled[cols_to_scale] = scaler.fit_transform(df_scaled[cols_to_scale])\n",
    "print(\"Applied MinMax scaling on:\", cols_to_scale)\n",
    "df_scaled[cols_to_scale].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Outlier Detection on `fare` using IQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'fare'\n",
    "Q1 = df[col].quantile(0.25)\n",
    "Q3 = df[col].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"{col} | Q1={Q1:.2f}, Q3={Q3:.2f}, IQR={IQR:.2f}\")\n",
    "print(f\"Lower bound={lower:.2f}, Upper bound={upper:.2f}\")\n",
    "\n",
    "df_no_outliers = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"Without outliers:\", df_no_outliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tidy & Clean Data\n",
    "\n",
    "- Fill missing values\n",
    "- Drop highly-missing column `deck`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# Fill missing age with median\n",
    "df_clean['age'] = df_clean['age'].fillna(df_clean['age'].median())\n",
    "\n",
    "# Fill embarked & embark_town with mode\n",
    "df_clean['embarked'] = df_clean['embarked'].fillna(df_clean['embarked'].mode()[0])\n",
    "df_clean['embark_town'] = df_clean['embark_town'].fillna(df_clean['embark_town'].mode()[0])\n",
    "\n",
    "# Drop 'deck' due to many missing values\n",
    "if 'deck' in df_clean.columns:\n",
    "    df_clean = df_clean.drop(columns=['deck'])\n",
    "\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"Cleaned shape:\", df_clean.shape)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Basic Statistical Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean of numeric columns:\")\n",
    "print(df_clean.mean(numeric_only=True))\n",
    "\n",
    "print(\"\\nAverage age by sex:\")\n",
    "print(df_clean.groupby('sex')['age'].mean())\n",
    "\n",
    "print(\"\\nSurvival rate by class:\")\n",
    "print(df_clean.groupby('class')['survived'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prepare Data for Prediction (Train/Test Split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_col = 'survived'\n",
    "X = df_clean.drop(target_col, axis=1)\n",
    "y = df_clean[target_col]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Simple Visualization Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of age\n",
    "sns.histplot(df_clean['age'], kde=True)\n",
    "plt.title('Age Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Survival count\n",
    "sns.countplot(x='survived', data=df_clean)\n",
    "plt.title('Survival Count')\n",
    "plt.show()\n",
    "\n",
    "# Fare vs Class\n",
    "sns.boxplot(x='class', y='fare', data=df_clean)\n",
    "plt.title('Fare by Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Machine Learning â€“ RandomForest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
